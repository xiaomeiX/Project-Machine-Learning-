{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 5: Neural Network\n",
    "Write your name\n",
    "* xiaomei Xie\n",
    "* Lili Hao\n",
    "\n",
    "In this phase, you will (1) construct neural network models to predict a response variable, (2) evaluate the\n",
    "model, and (3) write a report about what you find from the analysis. \n",
    "\n",
    "(a) Analysis of neural network models with varying number of hidden layers and number of units\n",
    "(nodes) in the hidden layers. (10 pts)\n",
    "\n",
    "(b) Analysis of the effects of different activation functions, such as relu, tanh, and logistic functions.\n",
    "(15 pts)\n",
    "\n",
    "(c) Analysis of optimal parameters and hyper-parameters, alpha value for regularization parameter,\n",
    "learning rate for gradient descent, the number of iterations, etc. (15 pts)\n",
    "\n",
    "For parameters and hyper-parameters, please see the details in Python Scikit. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e sure you install the following packages on your machine (No installation needed when you work on Google Colab)\n",
    "\n",
    "Requires the latest pip\n",
    "\n",
    "$ pip install --upgrade pip\n",
    "\n",
    "Current stable release for CPU and GF\n",
    "\n",
    "$ pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (2.4.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\xiexi\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\xiexi\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorflow) (3.15.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (49.6.0.post20200814)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.27.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\xiexi\\anaconda3\\envs\\cpsc5610\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import *\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "color_list_light = ['#FFFFAA', '#EFEFEF', '#AAFFAA', '#AAAAFF']\n",
    "color_list_bold = ['#EEEE00', '#000000', '#00CC00', '#0000CC']\n",
    "cmap_light = ListedColormap(color_list_light[0:2])\n",
    "cmap_bold  = ListedColormap(color_list_bold[0:2])\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)\n",
    "\n",
    "\n",
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=1, label=\"Step\")\n",
    "plt.plot(z, sigmoid(z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Activation functions\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.         -1.9798995  -1.95979899 -1.93969849 -1.91959799 -1.89949749\n",
      " -1.87939698 -1.85929648 -1.83919598 -1.81909548 -1.79899497 -1.77889447\n",
      " -1.75879397 -1.73869347 -1.71859296 -1.69849246 -1.67839196 -1.65829146\n",
      " -1.63819095 -1.61809045 -1.59798995 -1.57788945 -1.55778894 -1.53768844\n",
      " -1.51758794 -1.49748744 -1.47738693 -1.45728643 -1.43718593 -1.41708543\n",
      " -1.39698492 -1.37688442 -1.35678392 -1.33668342 -1.31658291 -1.29648241\n",
      " -1.27638191 -1.25628141 -1.2361809  -1.2160804  -1.1959799  -1.1758794\n",
      " -1.15577889 -1.13567839 -1.11557789 -1.09547739 -1.07537688 -1.05527638\n",
      " -1.03517588 -1.01507538 -0.99497487 -0.97487437 -0.95477387 -0.93467337\n",
      " -0.91457286 -0.89447236 -0.87437186 -0.85427136 -0.83417085 -0.81407035\n",
      " -0.79396985 -0.77386935 -0.75376884 -0.73366834 -0.71356784 -0.69346734\n",
      " -0.67336683 -0.65326633 -0.63316583 -0.61306533 -0.59296482 -0.57286432\n",
      " -0.55276382 -0.53266332 -0.51256281 -0.49246231 -0.47236181 -0.45226131\n",
      " -0.4321608  -0.4120603  -0.3919598  -0.3718593  -0.35175879 -0.33165829\n",
      " -0.31155779 -0.29145729 -0.27135678 -0.25125628 -0.23115578 -0.21105528\n",
      " -0.19095477 -0.17085427 -0.15075377 -0.13065327 -0.11055276 -0.09045226\n",
      " -0.07035176 -0.05025126 -0.03015075 -0.01005025  0.01005025  0.03015075\n",
      "  0.05025126  0.07035176  0.09045226  0.11055276  0.13065327  0.15075377\n",
      "  0.17085427  0.19095477  0.21105528  0.23115578  0.25125628  0.27135678\n",
      "  0.29145729  0.31155779  0.33165829  0.35175879  0.3718593   0.3919598\n",
      "  0.4120603   0.4321608   0.45226131  0.47236181  0.49246231  0.51256281\n",
      "  0.53266332  0.55276382  0.57286432  0.59296482  0.61306533  0.63316583\n",
      "  0.65326633  0.67336683  0.69346734  0.71356784  0.73366834  0.75376884\n",
      "  0.77386935  0.79396985  0.81407035  0.83417085  0.85427136  0.87437186\n",
      "  0.89447236  0.91457286  0.93467337  0.95477387  0.97487437  0.99497487\n",
      "  1.01507538  1.03517588  1.05527638  1.07537688  1.09547739  1.11557789\n",
      "  1.13567839  1.15577889  1.1758794   1.1959799   1.2160804   1.2361809\n",
      "  1.25628141  1.27638191  1.29648241  1.31658291  1.33668342  1.35678392\n",
      "  1.37688442  1.39698492  1.41708543  1.43718593  1.45728643  1.47738693\n",
      "  1.49748744  1.51758794  1.53768844  1.55778894  1.57788945  1.59798995\n",
      "  1.61809045  1.63819095  1.65829146  1.67839196  1.69849246  1.71859296\n",
      "  1.73869347  1.75879397  1.77889447  1.79899497  1.81909548  1.83919598\n",
      "  1.85929648  1.87939698  1.89949749  1.91959799  1.93969849  1.95979899\n",
      "  1.9798995   2.        ]\n"
     ]
    }
   ],
   "source": [
    "xrange = np.linspace(-2, 2, 200)\n",
    "print(xrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,6))\n",
    "\n",
    "# three commonly used activation functions, relu, tanh, and logistic\n",
    "plt.plot(xrange, np.maximum(xrange,0),label='relu')\n",
    "plt.plot(xrange, np.tanh(xrange),label='tanh')\n",
    "plt.plot(xrange, 1/(1+np.exp(-xrange)), label='logistic')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Neural network activation functions')\n",
    "plt.xlabel('Input value (x)')\n",
    "plt.ylabel('Activation function output')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_regions_for_classifier_subplot(clf, X, y, X_test, y_test, title, subplot, target_names = None, plot_decision_regions = True):\n",
    "###\n",
    "  #  numClasses = int(np.amax(y)) + 1\n",
    "    \n",
    "  #  print(numClasses)\n",
    "  #  color_list_light = ['#FFFFAA', '#EFEFEF', '#AAFFAA', '#AAAAFF']\n",
    "  #  color_list_bold = ['#EEEE00', '#000000', '#00CC00', '#0000CC']\n",
    "  #  cmap_light = ListedColormap(color_list_light[0:numClasses])\n",
    "   # cmap_bold  = ListedColormap(color_list_bold[0:numClasses])\n",
    "###\n",
    "    h = 0.03\n",
    "    k = 0.5\n",
    "    x_plot_adjust = 0.1\n",
    "    y_plot_adjust = 0.1\n",
    "    plot_symbol_size = 50\n",
    "\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "    x2, y2 = np.meshgrid(np.arange(x_min-k, x_max+k, h), np.arange(y_min-k, y_max+k, h))\n",
    "\n",
    "    P = clf.predict(np.c_[x2.ravel(), y2.ravel()])\n",
    "    P = P.reshape(x2.shape)\n",
    "\n",
    "    if plot_decision_regions:\n",
    "        subplot.contourf(x2, y2, P, cmap=cmap_light, alpha = 0.8)\n",
    "\n",
    "    subplot.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, s=plot_symbol_size, edgecolor = 'black')\n",
    "    subplot.set_xlim(x_min - x_plot_adjust, x_max + x_plot_adjust)\n",
    "    subplot.set_ylim(y_min - y_plot_adjust, y_max + y_plot_adjust)\n",
    "\n",
    "    if (X_test is not None):\n",
    "        subplot.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cmap_bold, s=plot_symbol_size, marker='^', edgecolor = 'black')\n",
    "        train_score = clf.score(X, y)\n",
    "        test_score  = clf.score(X_test, y_test)\n",
    "        title = title + \"\\nTrain score = {:.2f}, Test score = {:.2f}\".format(train_score, test_score)\n",
    "\n",
    "    subplot.set_title(title)\n",
    "\n",
    "    if (target_names is not None):\n",
    "        legend_handles = []\n",
    "        for i in range(0, len(target_names)):\n",
    "            patch = mpatches.Patch(color=color_list_bold[i], label=target_names[i])\n",
    "            legend_handles.append(patch)\n",
    "        subplot.legend(loc=0, handles=legend_handles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_regions_for_classifier(clf, X, y, X_test=None, y_test=None, title=None, target_names = None, plot_decision_regions = True):\n",
    "\n",
    "    #numClasses = np.amax(y) + 1\n",
    "  #  color_list_light = ['#FFFFAA', '#EFEFEF', '#AAFFAA', '#AAAAFF']\n",
    " #   color_list_bold = ['#EEEE00', '#000000', '#00CC00', '#0000CC']\n",
    "  #  cmap_light = ListedColormap(color_list_light[0:numClasses])\n",
    "  #  cmap_bold  = ListedColormap(color_list_bold[0:numClasses])\n",
    "\n",
    "    h = 0.03\n",
    "    k = 0.5\n",
    "    x_plot_adjust = 0.1\n",
    "    y_plot_adjust = 0.1\n",
    "    plot_symbol_size = 50\n",
    "\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "    x2, y2 = np.meshgrid(np.arange(x_min-k, x_max+k, h), np.arange(y_min-k, y_max+k, h))\n",
    "\n",
    "    P = clf.predict(np.c_[x2.ravel(), y2.ravel()])\n",
    "    P = P.reshape(x2.shape)\n",
    "    plt.figure()\n",
    "    if plot_decision_regions:\n",
    "        plt.contourf(x2, y2, P, cmap=cmap_light, alpha = 0.8)\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, s=plot_symbol_size, edgecolor = 'black')\n",
    "    plt.xlim(x_min - x_plot_adjust, x_max + x_plot_adjust)\n",
    "    plt.ylim(y_min - y_plot_adjust, y_max + y_plot_adjust)\n",
    "\n",
    "    if (X_test is not None):\n",
    "        plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cmap_bold, s=plot_symbol_size, marker='^', edgecolor = 'black')\n",
    "        train_score = clf.score(X, y)\n",
    "        test_score  = clf.score(X_test, y_test)\n",
    "        title = title + \"\\nTrain score = {:.2f}, Test score = {:.2f}\".format(train_score, test_score)\n",
    "\n",
    "    if (target_names is not None):\n",
    "        legend_handles = []\n",
    "        for i in range(0, len(target_names)):\n",
    "            patch = mpatches.Patch(color=color_list_bold[i], label=target_names[i])\n",
    "            legend_handles.append(patch)\n",
    "        plt.legend(loc=0, handles=legend_handles)\n",
    "\n",
    "    if (title is not None):\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KFold_report(X, y):\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    kf = KFold(n_splits=10, random_state=None, shuffle=True) # Define the split - into 2 folds \n",
    "    tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "    n=1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(\"=========================Kfold\" , n , \"=======================\")\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        tree_clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = tree_clf.predict(X_test)\n",
    "\n",
    "        # Print classification report\n",
    "        target_names = TARGET_NAMES\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        n = n+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick view of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport.Code</th>\n",
       "      <th>Airport.Name</th>\n",
       "      <th>Time.Label</th>\n",
       "      <th>Time.Month</th>\n",
       "      <th>Time.Month Name</th>\n",
       "      <th>Time.Year</th>\n",
       "      <th># of Delays.Carrier</th>\n",
       "      <th># of Delays.Late Aircraft</th>\n",
       "      <th># of Delays.National Aviation System</th>\n",
       "      <th># of Delays.Security</th>\n",
       "      <th>...</th>\n",
       "      <th>Flights.Total</th>\n",
       "      <th>Minutes Delayed.Carrier</th>\n",
       "      <th>Minutes Delayed.Late Aircraft</th>\n",
       "      <th>Minutes Delayed.National Aviation System</th>\n",
       "      <th>Minutes Delayed.Security</th>\n",
       "      <th>Minutes Delayed.Total</th>\n",
       "      <th>Minutes Delayed.Weather</th>\n",
       "      <th>Time.Month.level</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Ratio_Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta, GA: Hartsfield-Jackson Atlanta Intern...</td>\n",
       "      <td>2003/06</td>\n",
       "      <td>6</td>\n",
       "      <td>June</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.301513</td>\n",
       "      <td>0.270412</td>\n",
       "      <td>0.350472</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770892</td>\n",
       "      <td>0.258823</td>\n",
       "      <td>0.185741</td>\n",
       "      <td>0.194317</td>\n",
       "      <td>0.104668</td>\n",
       "      <td>0.260628</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.797538</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOS</td>\n",
       "      <td>Boston, MA: Logan International</td>\n",
       "      <td>2003/06</td>\n",
       "      <td>6</td>\n",
       "      <td>June</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.088067</td>\n",
       "      <td>0.093018</td>\n",
       "      <td>0.069295</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199003</td>\n",
       "      <td>0.066594</td>\n",
       "      <td>0.067780</td>\n",
       "      <td>0.037010</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.064041</td>\n",
       "      <td>0.053621</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.816993</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Airport.Code                                       Airport.Name Time.Label  \\\n",
       "0          ATL  Atlanta, GA: Hartsfield-Jackson Atlanta Intern...    2003/06   \n",
       "1          BOS                    Boston, MA: Logan International    2003/06   \n",
       "\n",
       "   Time.Month Time.Month Name  Time.Year  # of Delays.Carrier  \\\n",
       "0           6            June       2003             0.301513   \n",
       "1           6            June       2003             0.088067   \n",
       "\n",
       "   # of Delays.Late Aircraft  # of Delays.National Aviation System  \\\n",
       "0                   0.270412                              0.350472   \n",
       "1                   0.093018                              0.069295   \n",
       "\n",
       "   # of Delays.Security  ...  Flights.Total Minutes Delayed.Carrier  \\\n",
       "0              0.189474  ...       0.770892                0.258823   \n",
       "1              0.042105  ...       0.199003                0.066594   \n",
       "\n",
       "   Minutes Delayed.Late Aircraft  Minutes Delayed.National Aviation System  \\\n",
       "0                       0.185741                                  0.194317   \n",
       "1                       0.067780                                  0.037010   \n",
       "\n",
       "   Minutes Delayed.Security  Minutes Delayed.Total  Minutes Delayed.Weather  \\\n",
       "0                  0.104668               0.260628                 0.253219   \n",
       "1                  0.020004               0.064041                 0.053621   \n",
       "\n",
       "   Time.Month.level      Rate  Ratio_Rank  \n",
       "0               3.0  0.797538         2.0  \n",
       "1               3.0  0.816993         1.0  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../processeddata/new_airlines_Normalized.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Airport.Code', 'Airport.Name', 'Time.Label', 'Time.Month',\n",
       "       'Time.Month Name', 'Time.Year', '# of Delays.Carrier',\n",
       "       '# of Delays.Late Aircraft', '# of Delays.National Aviation System',\n",
       "       '# of Delays.Security', '# of Delays.Weather',\n",
       "       'Statistics.Carriers.Names', 'Carriers.Total', 'Flights.Cancelled',\n",
       "       'Flights.Delayed', 'Flights.Diverted', 'Flights.On Time',\n",
       "       'Flights.Total', 'Minutes Delayed.Carrier',\n",
       "       'Minutes Delayed.Late Aircraft',\n",
       "       'Minutes Delayed.National Aviation System', 'Minutes Delayed.Security',\n",
       "       'Minutes Delayed.Total', 'Minutes Delayed.Weather', 'Time.Month.level',\n",
       "       'Rate', 'Ratio_Rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4408, 27)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list_light = ['#FFFFAA', '#EFEFEF', '#AAFFAA', '#AAAAFF']\n",
    "color_list_bold = ['#EEEE00', '#000000', '#00CC00', '#0000CC']\n",
    "cmap_light = ListedColormap(color_list_light[0:2])\n",
    "cmap_bold  = ListedColormap(color_list_bold[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['# of Delays.Carrier','Time.Month',\n",
    "       '# of Delays.Late Aircraft', '# of Delays.National Aviation System',\n",
    "       '# of Delays.Security', '# of Delays.Weather',\n",
    "       'Flights.Cancelled',\n",
    "       'Flights.Delayed', 'Flights.Diverted', 'Flights.On Time',\n",
    "       'Flights.Total', 'Minutes Delayed.Carrier',\n",
    "       'Minutes Delayed.Late Aircraft',\n",
    "       'Minutes Delayed.National Aviation System', 'Minutes Delayed.Security',\n",
    "       'Minutes Delayed.Total', 'Minutes Delayed.Weather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = df[col].values\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30151261 6.         0.27041164 ... 0.10466761 0.26062804 0.25321933]\n",
      " [0.08806723 6.         0.09301797 ... 0.02000404 0.06404067 0.05362077]\n",
      " [0.06184874 6.         0.08892427 ... 0.05617296 0.05102322 0.08022262]\n",
      " ...\n",
      " [0.15058824 1.         0.19581533 ... 0.01333603 0.27073049 0.11579167]\n",
      " [0.07596639 1.         0.10325222 ... 0.01151748 0.06384675 0.04001356]\n",
      " [0.10016807 1.         0.05822151 ... 0.00747626 0.04414256 0.03319691]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"Ratio_Rank\"].values\n",
    "type(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 1., ..., 3., 1., 2.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(X))\n",
    "\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4408,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4408, 17)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title('Sample binary classification problem with non-linearly separable classes')\n",
    "plt.scatter( X[:,0], X[:,4],c=y,\n",
    "           marker= 'o', s=50, cmap=cmap_bold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply neural network with 2 hidden layers with varying number of units (10, 20, 50, 100). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2953, 17)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "<matplotlib.colors.ListedColormap object at 0x00000202AB4D3448>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but MLPRegressor is expecting 17 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-5c908595b464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcolor_list_light\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'#FFFFAA'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#EFEFEF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#AAFFAA'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#AAAAFF'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mListedColormap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_list_light\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnumClasses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mplot_class_regions_for_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Airline : Neural net classifier, 2 layers, 10/10 units'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-aac674a6651c>\u001b[0m in \u001b[0;36mplot_class_regions_for_classifier\u001b[1;34m(clf, X, y, X_test, y_test, title, target_names, plot_decision_regions)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_min\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_min\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CPSC5610\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1407\u001b[0m         \"\"\"\n\u001b[0;32m   1408\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pass_fast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CPSC5610\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass_fast\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \"\"\"\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m# Initialize first layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CPSC5610\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CPSC5610\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m             raise ValueError(\n\u001b[1;32m--> 366\u001b[1;33m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features, but MLPRegressor is expecting 17 features as input."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# model training with two hidden layers\n",
    "nnclf = MLPRegressor(hidden_layer_sizes = [10,20,50,100], solver='lbfgs',\n",
    "                     random_state = 0).fit(X_train, y_train)\n",
    "\n",
    "numClasses = int(np.amax(y)) + 1\n",
    "print(numClasses)\n",
    "color_list_light = ['#FFFFAA', '#EFEFEF', '#AAFFAA', '#AAAAFF']\n",
    "print(ListedColormap(color_list_light[0:numClasses]))\n",
    "plot_class_regions_for_classifier(nnclf, X_train, y_train, X_test, y_test, 'Airline : Neural net classifier, 2 layers, 10/10 units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Multivariate linear regression modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [x/10 for x in range(1, 9)]\n",
    "plt.figure()\n",
    "name = 'Multivariate linear regression modeling'\n",
    "mean_test_r2=[]\n",
    "mean_train_r2 = []\n",
    "for s in t:\n",
    "\n",
    "    train_R2_score = []\n",
    "    test_R2_score = []\n",
    "    y_pred = []\n",
    "    RMSE_score = []\n",
    "    for i in range(1,100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1-s)\n",
    "        #tree_clf.fit(X_train, y_train)\n",
    "        linreg = LinearRegression().fit(X_train, y_train)\n",
    "        train_R2_score.append(linreg.score(X_train, y_train))\n",
    "        test_R2_score.append(linreg.score(X_test, y_test))\n",
    "        yPred = linreg.predict(X_test)\n",
    "        y_pred.append(linreg.predict(X_test))\n",
    "        RMSE_score.append(np.sqrt(metrics.mean_squared_error(y_test, yPred)))\n",
    "    testR2 = np.mean(test_R2_score)\n",
    "    trainR2 = np.mean(train_R2_score)\n",
    "    mean_test_r2.append(testR2)\n",
    "    mean_train_r2.append(trainR2)\n",
    "    plt.plot(s, np.mean(test_R2_score), 'bo')\n",
    "    plt.plot(s, np.mean(train_R2_score), 'rx')\n",
    "    plt.legend(['train_R2_score', 'test_R2_score'], loc='best')\n",
    "    plt.title(name)\n",
    "        \n",
    "\n",
    "\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy')\n",
    "save_fig(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "    \n",
    "ax.set_title('Multivariate linear regression modeling')\n",
    "ax.set_xlabel(\"Training set proportion (%)\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(t, mean_test_r2, 'o-', color=\"r\", label=\"Mean Test score\")\n",
    "ax.plot(t, mean_train_r2, 'o-', color=\"g\", label=\"Mean Train score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('linear model original data intercept (b): {:.3f}'.format(linreg.intercept_))\n",
    "print('linear model original data coeff (w): {}'.format(linreg.coef_))\n",
    "\n",
    "# train data R2\n",
    "print('R-squared score (training): {:.3f}'.format(linreg.score(X_train, y_train)))\n",
    "# test data R2\n",
    "print('R-squared score (test): {:.3f}'.format(linreg.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set and print RMSE\n",
    "y_pred = linreg.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.bar(normalizedData[Xcol].columns, linreg.coef_, width=0.8, bottom=None, align='center')\n",
    "plt.title(\"coeffiences of linear regression\")\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "    \n",
    "# evaluate the training and testing and retrieve the information of model performance. \n",
    "\n",
    "train_sizes = np.linspace(0.2,0.8,5)  # 5 times 5*3 = 15\n",
    "\n",
    "train_sizes, train_mse, test_mse = learning_curve(linreg, X, y, \n",
    "                            train_sizes = train_sizes, \n",
    "                            scoring = 'neg_mean_squared_error',\n",
    "                                                 cv=3, shuffle=True)\n",
    "train_scores = np.sqrt(np.abs(train_mse))\n",
    "\n",
    "test_scores = np.sqrt(np.abs(test_mse))\n",
    "\n",
    "train_scores_mean=np.mean(train_scores, axis=1)\n",
    "\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "    \n",
    "ax.set_title('A learning curve for a simple linear regression')\n",
    "ax.set_xlabel(\"Training examples\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain theta using close form\n",
    "\n",
    "<img src=\"images/cf.png\" style=\"width: 200px;\">\n",
    "read pp. 118 - 122 of A. Geron textbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Multivariate linear regression model with gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "alpha = 0.01\n",
    "\n",
    "# number of iterations\n",
    "n_iter = 100\n",
    "\n",
    "# the number of data points\n",
    "n = 100\n",
    "\n",
    "# random initialization to theta. \n",
    "# Return samples (11 values for theta0 and theta1) from the “standard normal” distribution.\n",
    "theta = np.random.randn(11, 1)\n",
    "print('initial theta: \\n', theta)\n",
    "\n",
    "# the process of gradient descent\n",
    "for iteration in range(n_iter):\n",
    "    gradients = (1/n) * X_train.T.dot(X_train.dot(theta) - y_train)\n",
    "    theta = theta - alpha*gradients\n",
    "\n",
    "t = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "print('best theta: \\n', theta)\n",
    "#theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_R1)\n",
    "#print(theta_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train = []\n",
    "linridge = []\n",
    "r2_test = []\n",
    "num_coeff_bigger =[]\n",
    "alpha_Range = [0.2,0.4,0.6, 1, 5, 10, 15, 20, 25, 50, 75,100]\n",
    "for this_alpha in alpha_Range:\n",
    "    linridge_val = Ridge(alpha = this_alpha).fit(X_train, y_train)\n",
    "    linridge.append(linridge_val)\n",
    "    r2_train.append(linridge_val.score(X_train, y_train))\n",
    "    r2_test.append(linridge_val.score(X_test, y_test))\n",
    "    num_coeff_bigger.append(np.sum(abs(linridge_val.coef_) > 1.0))\n",
    "    #print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "#r-squared training: {:.2f}, r-squared test: {:.2f}\\n'\n",
    "         #.format(this_alpha, num_coeff_bigger, r2_train, r2_test))\n",
    "\n",
    "y_predict = X_test.dot(theta)\n",
    "\n",
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
    "    \n",
    "ax.set_title('Ridge regression: effect of alpha regularization parameter\\n')\n",
    "ax.set_xlabel(\"Alpha Range\")\n",
    "ax.set_ylabel(\"Score (R_2)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(alpha_Range, r2_train, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(alpha_Range, r2_test, 'o-', color=\"b\", label=\"Testing score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression using batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_Gradient_Descent(alpha):\n",
    "    # learning rate\n",
    "    print(\"alpha=============,\", alpha)\n",
    "    #alpha = 0.0001\n",
    "    #alpha = 0.0002\n",
    "\n",
    "    # number of iterations\n",
    "    #n_iter = 2000\n",
    "    n_iter = 200\n",
    "\n",
    "    # the number of data points\n",
    "    n = 11\n",
    "    theta = np.random.randn(11, 1)\n",
    "\n",
    "    preCost = sys.maxsize\n",
    "    bestCost = preCost\n",
    "\n",
    "    preTheta = np.random.randn(11, 1)\n",
    "    bestTheta = preTheta\n",
    "\n",
    "    changeCost = bestCost\n",
    "\n",
    "    # the process of gradient descent\n",
    "    for iteration in range(n_iter):\n",
    "        gradients = (1/n) * X_train.T.dot(X_train.dot(theta) - np.vstack(y_train))\n",
    "        theta = theta - alpha*gradients\n",
    "\n",
    "        cost = (X_train.dot(theta) - np.vstack(y_train)).T.dot(X_train.dot(theta) - np.vstack(y_train))[0][0] * (1/(2*n))\n",
    "        if preCost-cost>0:\n",
    "            bestCost = cost\n",
    "            bestTheta = theta\n",
    "            changeCost = preCost-cost\n",
    "            #print(preCost-cost)\n",
    "        else:\n",
    "            break\n",
    "            #print(preCost-cost)\n",
    "\n",
    "        preCost = cost\n",
    "        preTheta = theta    \n",
    "    print(\"bestCost:\",bestCost)\n",
    "    #print(bestTheta)\n",
    "    print(\"preCost-cost:\",changeCost)\n",
    "\n",
    "    theta = bestTheta\n",
    "    #print('best theta: \\n', theta)\n",
    "\n",
    "    y_train_predict = X_train.dot(theta)\n",
    "    train_error = np.sqrt(metrics.mean_squared_error(y_train, y_train_predict))\n",
    "    print('training RMSE: {:.3f}'.format(train_error))\n",
    "\n",
    "    y_test_predict = X_test.dot(theta)\n",
    "    test_error = np.sqrt(metrics.mean_squared_error(y_test, y_test_predict))\n",
    "    print('testing RMSE: {:.3f}\\n'.format(test_error))\n",
    "    \n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = X_test.dot(theta)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_sizes = [0.00001,0.0000125, 0.000015, 0.0000175, 0.00002, 0.000025,0.000030,0.000035, 0.000040,0.000045, \\\n",
    "               0.00005, 0.000075,0.0001,0.000125, 0.00015]#, 0.000175, 0.0002, 0.0005, 0.00075, 0.001]\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for alpha in alpha_sizes:\n",
    "    train_error, test_error= batch_Gradient_Descent(alpha)\n",
    "    print(train_error, test_error)\n",
    "    train_errors.append(train_error)\n",
    "    test_errors.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "ax.set_title('A learning curve for a Batch gradian regression')\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(alpha_sizes, train_errors, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(alpha_sizes, test_errors, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "for tick in ax.get_xticklabels(): \n",
    "    tick.set_rotation(25) \n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# learning rate\n",
    "#alpha = 0.0000125\n",
    "alpha = 0.0001\n",
    "#alpha = 0.0002\n",
    "\n",
    "# number of iterations\n",
    "n_iter = 10000\n",
    "#n_iter = 100\n",
    "\n",
    "# the number of data points\n",
    "n = 11\n",
    "theta = np.random.randn(11, 1)\n",
    "#theta = bestTheta\n",
    "\n",
    "preCost = sys.maxsize\n",
    "bestCost = preCost\n",
    "\n",
    "preTheta = np.random.randn(11, 1)\n",
    "bestTheta = preTheta\n",
    "\n",
    "changeCost = bestCost\n",
    "\n",
    "# the process of gradient descent\n",
    "for iteration in range(n_iter):\n",
    "    gradients = (1/n) * X_train.T.dot(X_train.dot(theta) - np.vstack(y_train))\n",
    "    theta = theta - alpha*gradients\n",
    "\n",
    "    cost = (X_train.dot(theta) - np.vstack(y_train)).T.dot(X_train.dot(theta) - np.vstack(y_train))[0][0] * (1/(2*n))\n",
    "    if preCost-cost>0:\n",
    "        bestCost = cost\n",
    "        bestTheta = theta\n",
    "        changeCost = preCost-cost\n",
    "        #print(preCost-cost)\n",
    "    else:\n",
    "        break\n",
    "        #print(preCost-cost)\n",
    "\n",
    "    preCost = cost\n",
    "    preTheta = theta    \n",
    "print(\"bestCost:\",bestCost)\n",
    "print(bestTheta)\n",
    "print(\"preCost-cost:\",changeCost)\n",
    "\n",
    "theta = bestTheta\n",
    "#print('best theta: \\n', theta)\n",
    "\n",
    "y_train_predict = X_train.dot(theta)\n",
    "train_error = np.sqrt(metrics.mean_squared_error(y_train, y_train_predict))\n",
    "print('training RMSE: {:.3f}'.format(train_error))\n",
    "\n",
    "y_test_predict = X_test.dot(theta)\n",
    "test_error = np.sqrt(metrics.mean_squared_error(y_test, y_test_predict))\n",
    "print('testing RMSE: {:.3f}\\n'.format(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def rsq(actual, predict):\n",
    "    corr_matrix = numpy.corrcoef(actual, predict)\n",
    "    corr = corr_matrix[0,1]\n",
    "    R_sq = corr**2\n",
    "\n",
    "    #print(R_sq)\n",
    "    return R_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = bestTheta\n",
    "#print('best theta: \\n', theta)\n",
    "\n",
    "train_score = rsq(y_train, np.hstack(y_train_predict))\n",
    "print('training R squared: {:.3f}'.format(train_score))\n",
    "\n",
    "y_train_predict = X_train.dot(theta)\n",
    "train_error = np.sqrt(metrics.mean_squared_error(y_train, y_train_predict))\n",
    "#print(np.hstack(y_train_predict))\n",
    "print('training RMSE: {:.3f}'.format(train_error))\n",
    "\n",
    "test_score = rsq(y_test, np.hstack(y_test_predict))\n",
    "print('testing R squared: {:.3f}'.format(test_score))\n",
    "\n",
    "y_test_predict = X_test.dot(theta)\n",
    "test_error = np.sqrt(metrics.mean_squared_error(y_test, y_test_predict))\n",
    "#print(np.hstack(y_test_predict))\n",
    "print('testing RMSE: {:.3f}\\n'.format(test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainin test splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = bestTheta\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "train_sizes = np.linspace(0.1, 0.90, 10)\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    # random initialization to theta. \n",
    "    # Return samples (11 values for theta0 and theta1) from the “standard normal” distribution.\n",
    "    test_size = 1 - train_size\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    print(\"test_size = : \", test_size)\n",
    "\n",
    "    y_train_predict = X_train.dot(theta)\n",
    "    train_error = np.sqrt(metrics.mean_squared_error(y_train, y_train_predict))\n",
    "    print('training RMSE: {:.3f}'.format(train_error))\n",
    "    train_errors.append(np.sqrt(train_error))\n",
    "\n",
    "    y_test_predict = X_test.dot(theta)\n",
    "    test_error = np.sqrt(metrics.mean_squared_error(y_test, y_test_predict))\n",
    "    print('testing RMSE: {:.3f}\\n'.format(test_error))\n",
    "    test_errors.append(np.sqrt(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "    \n",
    "ax.set_title('A learning curve for Batch Gradient Descent regression')\n",
    "ax.set_xlabel(\"Training examples\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(train_sizes, train_errors, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(train_sizes, test_errors, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack(theta)[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedData[Xcol].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bar chart for best theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.bar(normalizedData[Xcol].columns, np.hstack(theta)[0:], width=0.8, bottom=None, align='center')\n",
    "plt.title(\"Best Theta of Batch Gradient Descent\")\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Regularized linear regression models with feature normalization\n",
    "Ridge regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "print('Ridge regression: effect of alpha regularization parameter\\n')\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "train_R_sq= []\n",
    "test_R_sq = []\n",
    "\n",
    "alpha_sizes = [0, 0.0001, 0.001, 0.01, 0.02, 0.05, 0.075, 0.1,0.2]#,0.3,0.4, 0.5, 0.6, 0.7,0.8,0.9, 1]\n",
    "\n",
    "for this_alpha in alpha_sizes:\n",
    "    linridge = RidgeCV(alphas = [this_alpha],cv = 10).fit(X_train, y_train)\n",
    "    \n",
    "    r2_train = linridge.score(X_train, y_train)\n",
    "    train_R_sq.append(r2_train)\n",
    "    r2_test = linridge.score(X_test, y_test)\n",
    "    test_R_sq.append(r2_test)\n",
    "    num_coeff_bigger = np.sum(abs(linridge.coef_) > 1.0)\n",
    "    \n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "                    r-squared training: {:.2f}, r-squared test: {:.2f}'\n",
    "         .format(this_alpha, num_coeff_bigger, r2_train, r2_test))\n",
    "    \n",
    "    y_pred = linridge.predict(X_train)\n",
    "    train_error = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "    print('Training RMSE: {:.3f}'.format(train_error))\n",
    "    train_errors.append(train_error)\n",
    "\n",
    "    # make predictions on the testing set\n",
    "    y_pred = linridge.predict(X_test)\n",
    "    test_error = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Testing RMSE: {:.3f}\\n'.format(test_error))\n",
    "    test_errors.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "ax.set_title('A learning curve for a Ridge linear regression')\n",
    "ax.set_xlabel(\"Alpha number\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(alpha_sizes, train_errors, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(alpha_sizes, test_errors, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the parameter values for range of lower and upper bound of training data size\n",
    "# and the number of iterations, and see the changes in the learning curve. \n",
    "train_sizes = np.linspace(0.1, 0.90, 10)\n",
    "\n",
    "linridge = Ridge(alpha=0.01)\n",
    "\n",
    "train_sizes, train_mse, test_mse = \\\n",
    "            learning_curve(linridge, X, y, scoring='neg_mean_squared_error', \n",
    "                           train_sizes = train_sizes, cv=10, shuffle=True, random_state=1)\n",
    "    \n",
    "train_scores = np.sqrt(np.abs(train_mse))\n",
    "test_scores = np.sqrt(np.abs(test_mse))\n",
    "#print(train_scores)\n",
    "#print(test_scores)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "print(\"training RMSE: \",train_scores_mean)\n",
    "print(\"testing RMSE: \", test_scores_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "    \n",
    "ax.set_title('A learning curve for a Ridge regression')\n",
    "ax.set_xlabel(\"Training examples\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "r2_train = []\n",
    "linridge = []\n",
    "r2_test = []\n",
    "yPredicts = []\n",
    "rmse = []\n",
    "intercept_s = []\n",
    "coef_s = []\n",
    "\n",
    "\n",
    "alpha_Range = [0.001,0.005,0.01,0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5]\n",
    "\n",
    "\n",
    "\n",
    "for this_alpha in alpha_Range:\n",
    "    linridge_val = Ridge(alpha = this_alpha).fit(X_train, y_train)\n",
    "    linridge.append(linridge_val)\n",
    "    r2_train.append(linridge_val.score(X_train, y_train))\n",
    "    r2_test.append(linridge_val.score(X_test, y_test))\n",
    "    y_pred = linridge_val.predict(X_test)\n",
    "    yPredicts.append(y_pred)\n",
    "    rmse.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    intercept_s.append(linridge_val.intercept_)\n",
    "    coef_s.append(linridge_val.coef_)\n",
    "    #print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "#r-squared training: {:.2f}, r-squared test: {:.2f}\\n'\n",
    "         #.format(this_alpha, num_coeff_bigger, r2_train, r2_test))\n",
    "\n",
    "\n",
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
    "    \n",
    "ax.set_title('Airline dataset: Ridge regression model\\n')\n",
    "ax.set_xlabel(\"Alpha Range\")\n",
    "ax.set_ylabel(\"Score (R_2)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(alpha_Range, r2_train, 'o-', color=\"r\", label=\"R-squared score (training)\")\n",
    "ax.plot(alpha_Range, r2_test, 'o-', color=\"g\", label=\"R-squared score (test)\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "linridge = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1], cv = 10).fit(X, y)\n",
    "\n",
    "print('ridge regression linear model alpha: {}'.format(linridge.alpha_))\n",
    "print('ridge regression linear model intercept: {}'.format(linridge.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'.format(linridge.coef_))\n",
    "\n",
    "print('R-squared score (training): {:.3f}'.format(linridge.score(X_train, y_train)))\n",
    "\n",
    "print('R-squared score (test): {:.3f}'.format(linridge.best_score_))\n",
    "\n",
    "# make predictions on the testing set and print RMSE\n",
    "y_pred = linridge.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "linridge = Ridge(alpha=0.001).fit(X_train, y_train)\n",
    "\n",
    "print('Airline dataset')\n",
    "\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linridge.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "\n",
    "print('ridge regression linear model intercept: {}'.format(linridge.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'.format(linridge.coef_))\n",
    "\n",
    "print('Number of non-zero features: {}'.format(np.sum(linridge.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.bar(normalizedData[Xcol].columns, linridge.coef_, width=0.8, bottom=None, align='center')\n",
    "plt.title(\"coeffiences of Ridge Regression\")\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ridge regression: effect of alpha regularization parameter\\n')\n",
    "for this_alpha in [0, 1, 10, 20, 50, 100, 1000]:\n",
    "    linridge = Ridge(alpha = this_alpha).fit(X_train, y_train)\n",
    "    r2_train = linridge.score(X_train, y_train)\n",
    "    r2_test = linridge.score(X_test, y_test)\n",
    "    num_coeff_bigger = np.sum(abs(linridge.coef_) > 1.0)\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "r-squared training: {:.2f}, r-squared test: {:.2f}\\n'\n",
    "         .format(this_alpha, num_coeff_bigger, r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "linlasso = Lasso(alpha=0.001).fit(X_train, y_train)\n",
    "\n",
    "print('Airline dataset')\n",
    "\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linlasso.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linlasso.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "    \n",
    "print('lasso regression linear model intercept: {}'.format(linlasso.intercept_))\n",
    "print('lasso regression linear model coeff:\\n{}'.format(linlasso.coef_))\n",
    "\n",
    "print('Non-zero features: {}'.format(np.sum(linlasso.coef_ != 0)))\n",
    " \n",
    "print('Features with non-zero weight (sorted by absolute magnitude):')\n",
    "for e in sorted (list(zip(list(X), linlasso.coef_)),\n",
    "                key = lambda e: -abs(e[1])):\n",
    "    if e[1] != 0:\n",
    "        print('\\t{}, {:.3f}'.format(e[0], e[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso with different lambdas\n",
    "Apply the Lasso regression on the training set with the following λ parameters: (0.0001, 0.0005, 0.0007,0.001,0.002, 0.004, 0.007, 0.01, 0.015,0.02). Evaluate the R^2 score for all the models you obtain on both the train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot values as function of lambda \n",
    "Plot all values for both data sets (train and test \n",
    "R2-values) as a function of λ. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = (0.001, 0.01, 0.1, 0.5, 1, 2, 10)\n",
    "l_num = 7\n",
    "pred_num = X.shape[1]\n",
    "\n",
    "# prepare data for enumerate\n",
    "coeff_a = np.zeros((l_num, pred_num))\n",
    "train_r_squared = np.zeros(l_num)\n",
    "test_r_squared = np.zeros(l_num)\n",
    "# enumerate through lambdas with index and i\n",
    "for ind, i in enumerate(lambdas):    \n",
    "    reg = Lasso(alpha = i)\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    #coeff_a[ind,:] = reg.coef_\n",
    "    train_r_squared[ind] = reg.score(X_train, y_train)\n",
    "    test_r_squared[ind] = reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.plot(train_r_squared, 'bo-', label=r'$R^2$ Training set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
    "plt.plot(test_r_squared, 'bo-', label=r'$R^2$ Test set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
    "plt.xlabel('Lamda index'); plt.ylabel(r'$R^2$')\n",
    "plt.xlim(0, 6)\n",
    "plt.title(r'Evaluate lasso regression with lamdas: 0 = 0.001, 1= 0.01, 2 = 0.1, 3 = 0.5, 4= 1, 5= 2, 6 = 10')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train = []\n",
    "r2_test = []\n",
    "\n",
    "feature_kept = []\n",
    "\n",
    "\n",
    "alpha_list=[0.0001, 0.0005, 0.0007,0.001,0.002, 0.004, 0.007, 0.01, 0.015,0.02]\n",
    "\n",
    "for alpha in alpha_list :\n",
    "    linlasso = Lasso(alpha, max_iter = 10000).fit(X_train, y_train)\n",
    "    r2_train.append(linlasso.score(X_train, y_train))\n",
    "    r2_test.append(linlasso.score(X_test, y_test))\n",
    "    feature_kept.append(np.sum(linlasso.coef_ != 0))\n",
    "    \n",
    "    #print('Alpha = {:.2f}\\nFeatures kept: {}, r-squared training: {:.2f}, \\\n",
    "#r-squared test: {:.2f}\\n'\n",
    "         #.format(alpha, np.sum(linlasso.coef_ != 0), r2_train, r2_test))\n",
    "    \n",
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
    "    \n",
    "ax.set_title('Lasso regression: effect of alpha regularization\\n\\\n",
    "            parameter on number of features kept in final model\\n')\n",
    "ax.set_xlabel(\"Alpha Range\")\n",
    "ax.set_ylabel(\"Score (R_2)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(alpha_list, r2_train, 'o-', color=\"r\", label=\"R-squared score (training)\")\n",
    "ax.plot(alpha_list, r2_test, 'o-', color=\"g\", label=\"R-squared score (test)\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify best lambda and coefficients\n",
    "Store your test data results in a DataFrame and indentify the lambda where the \n",
    "R\n",
    "2\n",
    " has it’s maximum value in the test data. Fit a Lasso model with this lambda parameter (use the training data) and obtain the corresponding regression coefficients. Furthermore, obtain the mean squared error for the test data of this model (module: from sklearn.metrics import mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lam = pd.DataFrame(test_r_squared*100, columns=['R_squared'])\n",
    "df_lam['lambda'] = (lambdas)\n",
    "# returns the index of the row where column has maximum value.\n",
    "df_lam.loc[df_lam['R_squared'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of best model\n",
    "reg_best = Lasso(alpha = 0.1)\n",
    "reg_best.fit(X_train, y_train)\n",
    "reg_best.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, reg_best.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation \n",
    "Evaluate the performance of a Lasso regression for different regularization parameters λ using 5-fold cross validation on the training set (module: from sklearn.model_selection import cross_val_score) and plot the cross-validation (CV) R2 scores of the training and test data as a function of λ.\n",
    "Use the following lambda parameters: l_min = 0.05 l_max = 0.2 l_num = 20 lambdas = np.linspace(l_min,l_max, l_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_min = 0.05\n",
    "l_max = 0.2\n",
    "l_num = 20\n",
    "lambdas = np.linspace(l_min,l_max, l_num)\n",
    "\n",
    "train_r_squared = np.zeros(l_num)\n",
    "test_r_squared = np.zeros(l_num)\n",
    "\n",
    "pred_num = X.shape[1]\n",
    "coeff_a = np.zeros((l_num, pred_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for ind, i in enumerate(lambdas):    \n",
    "    reg = Lasso(alpha = i)\n",
    "    reg.fit(X_train, y_train)\n",
    "    results = cross_val_score(reg, X, y, cv=5, scoring=\"r2\")\n",
    "\n",
    "    train_r_squared[ind] = reg.score(X_train, y_train)    \n",
    "    test_r_squared[ind] = reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.plot(train_r_squared, 'bo-', label=r'$R^2$ Training set', color=\"darkblue\", alpha=0.6, linewidth=3)\n",
    "plt.plot(test_r_squared, 'bo-', label=r'$R^2$ Test set', color=\"darkred\", alpha=0.6, linewidth=3)\n",
    "plt.xlabel('Lamda value'); plt.ylabel(r'$R^2$')\n",
    "plt.xlim(0, 19)\n",
    "plt.title(r'Evaluate 5-fold cv with different lamdas')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Best Model\n",
    "Finally, store your test data results in a DataFrame and identify the lambda where the \n",
    "R\n",
    "2\n",
    " has it’s maximum value in the test data. Fit a Lasso model with this lambda parameter (use the training data) and obtain the corresponding regression coefficients. Furthermore, obtain the mean squared error for the test data of this model (module: from sklearn.metrics import mean_squared_error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lam = pd.DataFrame(test_r_squared*100, columns=['R_squared'])\n",
    "df_lam['lambda'] = (lambdas)\n",
    "# returns the index of the row where column has maximum value.\n",
    "df_lam.loc[df_lam['R_squared'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "reg_best = Lasso(alpha = 0.00001)\n",
    "reg_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, reg_best.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_best.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.bar(normalizedData[Xcol].columns, reg_best.coef_, width=0.8, bottom=None, align='center')\n",
    "plt.title(\"coeffiences of Lasso Regression\")\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "linlasso = LassoCV(alphas=[1e-6,1e-5,1e-4,1e-3, 1e-2, 1e-1, 1], cv = 10).fit(X, y)\n",
    "\n",
    "print('ridge regression linear model alpha: {}'.format(linlasso.alpha_))\n",
    "print('ridge regression linear model intercept: {}'.format(linlasso.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'.format(linlasso.coef_))\n",
    "\n",
    "print('R-squared score (training): {:.3f}'.format(linlasso.score(X_train, y_train)))\n",
    "\n",
    "print('R-squared score (test): {:.3f}'.format(linlasso.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set and print RMSE\n",
    "y_pred = linlasso.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.bar(normalizedData[Xcol].columns, linlasso.coef_, width=0.8, bottom=None, align='center')\n",
    "plt.title(\"coeffiences of Lasso Regression\")\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Polynomial regression models \n",
    "a). LinearRegression : Degree, Learing Curve, R-squart, K cross validation\n",
    "\n",
    "b). Ridge Regression : Degree, Alpha, Learing Curve, R-squart, K cross validation\n",
    "\n",
    "c). Lasso Regression : Degree Alpha, Learing Curve, R-squart, K cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# change the parameter values for range of lower and upper bound of training data size\n",
    "# and the number of iterations, and see the changes in the learning curve. \n",
    "degree_sizes = [1, 2, 3]\n",
    "train_scores_mean = []\n",
    "test_scores_mean = []\n",
    "for degree in degree_sizes:\n",
    "    print(\"degree =\", degree)\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=0)\n",
    "    #print(degree)\n",
    "    \n",
    "    linreg_poly = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    #==================================================================================\n",
    "    #print('(poly deg 2) linear model coeff (w):\\n{}'\n",
    "     #    .format(linreg_poly.coef_))\n",
    "    #print('(poly deg 2) linear model intercept (b): {:.3f}'\n",
    "    #     .format(linreg_poly.intercept_))\n",
    "    print('(poly deg ', linreg_poly, ') R-squared score (training): {:.3f}'\n",
    "         .format(linreg_poly.score(X_train, y_train)))\n",
    "    print('(poly deg ', linreg_poly, ') R-squared score (test): {:.3f}'\n",
    "         .format(linreg_poly.score(X_test, y_test)))\n",
    "    \n",
    "    y_pred = linreg_poly.predict(X_train)\n",
    "    train_score_mean = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "    print('Training RMSE: {:.3f}'.format(train_score_mean))\n",
    "    train_scores_mean.append(train_score_mean)\n",
    "\n",
    "    # make predictions on the testing set\n",
    "    y_pred = linreg_poly.predict(X_test)\n",
    "    test_score_mean = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Testing RMSE: {:.3f}\\n'.format(test_score_mean))\n",
    "    test_scores_mean.append(test_score_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "ax.set_title('A learning curve for a Polynomial regression')\n",
    "ax.set_xlabel(\"Degree\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(degree_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(degree_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A learning curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "    \n",
    "# change the parameter values for range of lower and upper bound of training data size\n",
    "# and the number of iterations, and see the changes in the learning curve. \n",
    "\n",
    "linreg_poly = LinearRegression()\n",
    "\n",
    "train_sizes = np.linspace(0.1, 0.90, 10)\n",
    "\n",
    "train_sizes, train_mse, test_mse = \\\n",
    "            learning_curve(linreg_poly, X, y, scoring='neg_mean_squared_error', \n",
    "                           train_sizes = train_sizes, cv=10, shuffle=True, random_state=1)\n",
    "    \n",
    "train_scores = np.sqrt(np.abs(train_mse))\n",
    "test_scores = np.sqrt(np.abs(test_mse))\n",
    "#print(train_scores)\n",
    "#print(test_scores)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "print(\"training RMSE: \",train_scores_mean)\n",
    "print(\"testing RMSE: \", test_scores_mean)\n",
    "\n",
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "    \n",
    "ax.set_title('A learning curve for a Polynomial regression')\n",
    "ax.set_xlabel(\"Training examples\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-Squart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_poly = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "#print('(poly deg 2) linear model coeff (w):\\n{}'\n",
    " #    .format(linreg_poly.coef_))\n",
    "#print('(poly deg 2) linear model intercept (b): {:.3f}'\n",
    "#     .format(linreg_poly.intercept_))\n",
    "print('(poly deg 2) R-squared score (training): {:.3f}'\n",
    "     .format(linreg_poly.score(X_train, y_train)))\n",
    "print('(poly deg 2) R-squared score (test): {:.3f}'\n",
    "     .format(linreg_poly.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linreg_poly.predict(X_test)\n",
    "print('(poly deg 2) RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(linreg_poly, X_train, y_train, cv=10)\n",
    "#print(score)\n",
    "#print(score.sum()/10)\n",
    "\n",
    "#print('linear model original data intercept (b): {:.3f}'.format(linreg_poly.intercept_))\n",
    "#print('linear model original data coeff (w): {}'.format(linreg_poly.coef_))\n",
    "\n",
    "# train data R2\n",
    "print('(poly deg 2) R-squared score (training): {:.3f}'.format(score.sum()/10))\n",
    "# test data R2\n",
    "print('(poly deg 2) R-squared score (test): {:.3f}'.format(linreg_poly.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set and print RMSE\n",
    "y_pred = linreg_poly.predict(X_test)\n",
    "print('(poly deg 2) RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the parameter values for range of lower and upper bound of training data size\n",
    "# and the number of iterations, and see the changes in the learning curve. \n",
    "degree_sizes = [1, 2, 3, 4]#, 5]\n",
    "train_scores_mean = []\n",
    "test_scores_mean = []\n",
    "for degree in degree_sizes:\n",
    "    print(\"degree =\", degree)\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=0)\n",
    "    #print(degree)\n",
    "    \n",
    "    linrig_poly = Ridge(alpha = 0.01).fit(X_train, y_train)\n",
    "    \n",
    "    train_score = linrig_poly.score(X_train, y_train)\n",
    "    print('(poly deg ', linrig_poly, ') R-squared score (training): {:.3f}'\n",
    "         .format(train_score))\n",
    "    test_score = linrig_poly.score(X_test, y_test)\n",
    "    print('(poly deg ', linrig_poly, ') R-squared score (test): {:.3f}'\n",
    "         .format(test_score))\n",
    "    \n",
    "    y_pred = linrig_poly.predict(X_train)\n",
    "    train_score_mean = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "    print('Training RMSE: {:.3f}'.format(train_score_mean))\n",
    "    train_scores_mean.append(train_score_mean)\n",
    "\n",
    "    # make predictions on the testing set\n",
    "    y_pred = linrig_poly.predict(X_test)\n",
    "    test_score_mean = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Testing RMSE: {:.3f}\\n'.format(test_score_mean))\n",
    "    test_scores_mean.append(test_score_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "ax.set_title('A learning curve for a Polynomial Ridge regression')\n",
    "ax.set_xlabel(\"Degree\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(degree_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(degree_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = []\n",
    "test_scores_mean = []\n",
    "\n",
    "alpha_sizes = [0, 0.0001, 0.001, 0.01, 0.02, 0.05, 0.075, 0.1,0.2,0.3,0.4, 0.5, 0.6, 0.7,0.8,0.9, 1,2,]\n",
    "\n",
    "for this_alpha in alpha_sizes:\n",
    "    linrig_poly = Ridge(alpha = this_alpha).fit(X_train, y_train)\n",
    "    r2_train = linrig_poly.score(X_train, y_train)\n",
    "    r2_test = linrig_poly.score(X_test, y_test)\n",
    "    num_coeff_bigger = np.sum(abs(linrig_poly.coef_) > 1.0)\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "r-squared training: {:.2f}, r-squared test: {:.2f}'\n",
    "         .format(this_alpha, num_coeff_bigger, r2_train, r2_test))\n",
    "    \n",
    "    y_pred = linrig_poly.predict(X_train)\n",
    "    train_score_mean = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "    print('Training RMSE: {:.3f}'.format(train_score_mean))\n",
    "    train_scores_mean.append(train_score_mean)\n",
    "\n",
    "    # make predictions on the testing set\n",
    "    y_pred = linrig_poly.predict(X_test)\n",
    "    test_score_mean = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Testing RMSE: {:.3f}\\n'.format(test_score_mean))\n",
    "    test_scores_mean.append(test_score_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "ax.set_title('A learning curve for a Polynomial Ridge regression')\n",
    "ax.set_xlabel(\"Alpha number\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(alpha_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(alpha_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "    \n",
    "# change the parameter values for range of lower and upper bound of training data size\n",
    "# and the number of iterations, and see the changes in the learning curve. \n",
    "linrig_poly = Ridge(alpha = 0.01)\n",
    "\n",
    "train_sizes = np.linspace(0.1, 0.90, 10)\n",
    "\n",
    "train_sizes, train_mse, test_mse = \\\n",
    "            learning_curve(linrig_poly, X, y, scoring='neg_mean_squared_error', \n",
    "                           train_sizes = train_sizes, cv=10, shuffle=True, random_state=1)\n",
    "    \n",
    "train_scores = np.sqrt(np.abs(train_mse))\n",
    "test_scores = np.sqrt(np.abs(test_mse))\n",
    "#print(train_scores)\n",
    "#print(test_scores)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "print(\"training RMSE: \",train_scores_mean)\n",
    "print(\"testing RMSE: \", test_scores_mean)\n",
    "\n",
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "    \n",
    "ax.set_title('A learning curve for a Polynomial Ridge regression')\n",
    "ax.set_xlabel(\"Training examples\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=0)\n",
    "\n",
    "linridge_poly = Ridge(alpha = 0.01).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Airline dataset')\n",
    "\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge_poly.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge_poly.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linridge_poly.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "\n",
    "#print('ridge regression linear model intercept: {}'.format(linridge.intercept_))\n",
    "#print('ridge regression linear model coeff:\\n{}'.format(linridge.coef_))\n",
    "\n",
    "print('Number of non-zero features: {}'.format(np.sum(linridge_poly.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(linridge_poly, X_train, y_train, cv=10)\n",
    "\n",
    "# train data R2\n",
    "print('R-squared score (training): {:.3f}'.format(score.sum()/10))\n",
    "# test data R2\n",
    "print('R-squared score (test): {:.3f}'.format(linridge_poly.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set and print RMSE\n",
    "y_pred = linridge_poly.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Ridge regression: effect of alpha regularization parameter\\n')\n",
    "for this_alpha in [0, 0.01, 0.05, 0.075, 0.1, 0.5, 1, 10, 20, 50, 100, 1000]:\n",
    "    linridge = Ridge(alpha = this_alpha).fit(X_train, y_train)\n",
    "    r2_train = linridge.score(X_train, y_train)\n",
    "    r2_test = linridge.score(X_test, y_test)\n",
    "    num_coeff_bigger = np.sum(abs(linridge.coef_) > 1.0)\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "r-squared training: {:.2f}, r-squared test: {:.2f}\\n'\n",
    "         .format(this_alpha, num_coeff_bigger, r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the parameter values for range of lower and upper bound of training data size\n",
    "# and the number of iterations, and see the changes in the learning curve. \n",
    "degree_sizes = [1, 2, 3, 4, 5, 6]#, 7, 8, 9]\n",
    "\n",
    "train_scores_mean = []\n",
    "test_scores_mean = []\n",
    "\n",
    "for degree in degree_sizes:\n",
    "    print(\"degree =\", degree)\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=0)\n",
    "    \n",
    "    linlasso_poly = Lasso(alpha = 0.000001).fit(X_train, y_train)\n",
    "\n",
    "    train_score = linlasso_poly.score(X_train, y_train)\n",
    "    print('(poly deg ', linlasso_poly, ') R-squared score (training): {:.3f}'\n",
    "         .format(train_score))\n",
    "    test_score = linlasso_poly.score(X_test, y_test)\n",
    "    print('(poly deg ', linlasso_poly, ') R-squared score (test): {:.3f}'\n",
    "         .format(test_score))\n",
    "    \n",
    "    y_pred = linlasso_poly.predict(X_train)\n",
    "    train_score_mean = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "    print('Training RMSE: {:.3f}'.format(train_score_mean))\n",
    "    train_scores_mean.append(train_score_mean)\n",
    "\n",
    "    # make predictions on the testing set\n",
    "    y_pred = linlasso_poly.predict(X_test)\n",
    "    test_score_mean = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Testing RMSE: {:.3f}\\n'.format(test_score_mean))\n",
    "    test_scores_mean.append(test_score_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learing Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "ax.set_title('A learning curve for a polynomial Lasso regression')\n",
    "ax.set_xlabel(\"Degree\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(degree_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(degree_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lasso regression: effect of alpha regularization\\n\\\n",
    "parameter on number of features kept in final model\\n')\n",
    "\n",
    "train_scores_mean = []\n",
    "test_scores_mean = []\n",
    "\n",
    "#alpha_sizes = [0.0, 0.001, 0.01, 0.025, 0.05, 0.075, 0.25, 0.5, 1, 5]\n",
    "alpha_sizes =  [0.0, 0.0000001,0.0000005,0.000001,0.000005, 0.00001,0.00005, 0.0001]\n",
    "\n",
    "for alpha in alpha_sizes:\n",
    "    linlasso_poly = Lasso(alpha, max_iter = 10000).fit(X_train, y_train)\n",
    "    r2_train = linlasso_poly.score(X_train, y_train)\n",
    "    r2_test = linlasso_poly.score(X_test, y_test)\n",
    "    \n",
    "    print('Alpha = {:.8f}\\nFeatures kept: {}, r-squared training: {:.8f}, \\\n",
    "r-squared test: {:.8f}'\n",
    "         .format(alpha, np.sum(linlasso_poly.coef_ != 0), r2_train, r2_test))\n",
    "    \n",
    "    y_pred = linlasso_poly.predict(X_train)\n",
    "    train_score_mean = np.sqrt(metrics.mean_squared_error(y_train, y_pred))\n",
    "    print('Training RMSE: {:.5f}'.format(train_score_mean))\n",
    "    train_scores_mean.append(train_score_mean)\n",
    "\n",
    "    # make predictions on the testing set\n",
    "    y_pred = linlasso_poly.predict(X_test)\n",
    "    test_score_mean = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Testing RMSE: {:.5f}\\n'.format(test_score_mean))\n",
    "    test_scores_mean.append(test_score_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "ax.set_title('A learning curve for a Polynomial Lasso regression')\n",
    "ax.set_xlabel(\"Alpha number\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(alpha_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(alpha_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train size/ Testing Size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "    \n",
    "# change the parameter values for range of lower and upper bound of training data size\n",
    "# and the number of iterations, and see the changes in the learning curve. \n",
    "\n",
    "linlasso_poly = Lasso(alpha = 0.000001)\n",
    "\n",
    "train_sizes = np.linspace(0.2, 0.90, 10)\n",
    "\n",
    "train_sizes, train_mse, test_mse = \\\n",
    "            learning_curve(linlasso_poly, X, y, scoring='neg_mean_squared_error', \n",
    "                           train_sizes = train_sizes, cv=10, shuffle=True, random_state=1)\n",
    "    \n",
    "train_scores = np.sqrt(np.abs(train_mse))\n",
    "test_scores = np.sqrt(np.abs(test_mse))\n",
    "#print(train_scores)\n",
    "#print(test_scores)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "print(\"training RMSE: \",train_scores_mean)\n",
    "print(\"testing RMSE: \", test_scores_mean)\n",
    "\n",
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "    \n",
    "ax.set_title('A learning curve for a Polynomial Lasso regression')\n",
    "ax.set_xlabel(\"Training examples\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "linlasso_poly = Lasso(alpha = 0.000001).fit(X_train, y_train)\n",
    "\n",
    "print('Airline dataset')\n",
    "\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso_poly.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linlasso_poly.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linlasso_poly.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "    \n",
    "#print('lasso regression linear model intercept: {}'.format(linlasso.intercept_))\n",
    "#print('lasso regression linear model coeff:\\n{}'.format(linlasso.coef_))\n",
    "\n",
    "print('Non-zero features: {}\\n'.format(np.sum(linlasso_poly.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(linlasso_poly, X_train, y_train, cv=10)\n",
    "#print(score)\n",
    "#print(score.sum()/10)\n",
    "\n",
    "#print('linear model original data intercept (b): {:.3f}'.format(linreg_poly.intercept_))\n",
    "#print('linear model original data coeff (w): {}'.format(linreg_poly.coef_))\n",
    "\n",
    "# train data R2\n",
    "print('R-squared score (training): {:.3f}'.format(score.sum()/10))\n",
    "# test data R2\n",
    "print('R-squared score (test): {:.3f}'.format(linlasso_poly.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set and print RMSE\n",
    "y_pred = linlasso_poly.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "linlasso = Lasso(alpha = 0.00001).fit(X_train, y_train)\n",
    "\n",
    "print('Airline dataset')\n",
    "\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linlasso.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linlasso.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "    \n",
    "print('lasso regression linear model intercept: {}'.format(linlasso.intercept_))\n",
    "print('lasso regression linear model coeff:\\n{}'.format(linlasso.coef_))\n",
    "\n",
    "print('Non-zero features: {}'.format(np.sum(linlasso.coef_ != 0)))\n",
    " \n",
    "print('Features with non-zero weight (sorted by absolute magnitude):')\n",
    "for e in sorted (list(zip(list(X), linlasso.coef_)),\n",
    "                key = lambda e: -abs(e[1])):\n",
    "    if e[1] != 0:\n",
    "        print('\\t{}, {:.3f}'.format(e[0], e[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lasso regression: effect of alpha regularization\\n\\\n",
    "parameter on number of features kept in final model\\n')\n",
    "\n",
    "for alpha in [0.0,0.001, 0.01, 0.025, 0.05, 0.075, 0.25, 0.5, 1, 2, 3, 5, 10, 20, 50]:\n",
    "    linlasso = Lasso(alpha, max_iter = 10000).fit(X_train, y_train)\n",
    "    r2_train = linlasso.score(X_train, y_train)\n",
    "    r2_test = linlasso.score(X_test, y_test)\n",
    "    \n",
    "    print('Alpha = {:.2f}\\nFeatures kept: {}, r-squared training: {:.2f}, \\\n",
    "r-squared test: {:.2f}\\n'\n",
    "         .format(alpha, np.sum(linlasso.coef_ != 0), r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
